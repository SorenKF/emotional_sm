{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('emsub': conda)",
   "display_name": "Python 3.8.5 64-bit ('emsub': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c8a63e31ffb1a3adb15a5de85a1df3b507cd69b37963f70a13abe50a567902a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Concate train and test files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all TRAC test and gold data. Whoops...\n",
    "\n",
    "\n",
    "trac_fb = pd.read_csv('../Data/TRAC2018_full/converted/trac-gold-set/agr_en_fb_gold.csv')\n",
    "trac_sm = pd.read_csv('../Data/TRAC2018_full/converted/trac-gold-set/agr_en_tw_gold.csv')\n",
    "\n",
    "frames = [trac_fb, trac_sm]\n",
    "df_trac_test_combined = pd.concat(frames)\n",
    "\n",
    "\n",
    "df_trac_test_combined.to_csv('../Data/TRAC2018_full/converted/trac-gold-set/agr_en_combined_gold.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['label']",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-df69fa762c36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#pd.read_csv('../Data/gibert_vua_format/trainData.csv', sep='\\t')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/hate_speech_mlma/MLMA_convert/level1/test.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2052\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m             ):\n\u001b[1;32m-> 2054\u001b[1;33m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[1;34m(usecols, names)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1303\u001b[0m             \u001b[1;34mf\"Usecols do not match columns, columns expected but not found: {missing}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['label']"
     ]
    }
   ],
   "source": [
    "#pd.read_csv('../Data/gibert_vua_format/trainData.csv', sep='\\t')\n",
    "pd.read_csv('../Data/hate_speech_mlma/MLMA_convert/level1/test.tsv', sep='\\t', usecols=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nFalse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def has_duplicated(l):\n",
    "    return pd.Series(l).duplicated().sum() > 0\n",
    "\n",
    "print(has_duplicated(['one', 'two', 'one']))\n",
    "# True\n",
    "print(has_duplicated(['one', 'two', 'three']))\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(train_file, test_file, type='csv'):\n",
    "    '''Concat and convert VUA data to pickle files for Deepmoji.\n",
    "\n",
    "    Args: \n",
    "        train_file (str): filepath to a training datafile.\n",
    "        test_file (str): filepath to a test_file.\n",
    "    \n",
    "    Optional:\n",
    "        type (str): specify data file format (default is .csv)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # 1. Load the data\n",
    "\n",
    "    cols_to_use = ['text', 'label']\n",
    "    df_train = pd.read_csv(train_file, usecols=cols_to_use)\n",
    "    df_test = pd.read_csv(test_file, usecols=cols_to_use)\n",
    "\n",
    "    #print(len(df_train), len(df_test))\n",
    "\n",
    "    # Concat'em\n",
    "    frames = [df_train, df_test]\n",
    "    df_train_and_test = pd.concat(frames)\n",
    "\n",
    "    # Rename columns to deepmoji's format.\n",
    "    df_train_and_test.rename({'text': 'texts', 'label':'info'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Modify info column values 'str' -> {'label':label}\n",
    "    df_train_and_test['info'] = df_train_and_test['info'].apply(lambda x: {'label' : x})\n",
    "    \n",
    "    # Add the extra index columns\n",
    "    extra_index_cols =  ['train_ind', 'test_ind', 'val_ind']\n",
    "    df_train_and_test = df_train_and_test.join(pd.DataFrame(columns=extra_index_cols)) #.fillna(np.nan)\n",
    "    \n",
    "\n",
    "    # 2. Construct dict for pickeling.\n",
    "    # Get indeces\n",
    "\n",
    "    # Split original train data into train and validation sets.\n",
    "    org_train_ind = (range(0, len(df_train)))\n",
    "\n",
    "    train_val_split = train_test_split(org_train_ind, test_size=0.1)\n",
    "    train_ind = train_val_split[0]\n",
    "    val_ind = train_val_split[1]\n",
    "\n",
    "    # Add new train indeces.\n",
    "    #df_train_and_test['train_ind'] = df_train_and_test['train_ind'].add(train_ind, ignore_index=True)\n",
    "    #df_train_and_test['train_ind'] = pd.Series(train_ind) # this used to work..\n",
    "    df_train_and_test.iloc[:len(train_ind):, 2] = train_ind\n",
    "\n",
    "    # Add val indeces\n",
    "    #df_train_and_test['val_ind'] = pd.Series(val_ind) # this used to work.\n",
    "    df_train_and_test.iloc[:len(val_ind):, 4] = val_ind\n",
    "\n",
    "    # Add test indeces\n",
    "    test_ind = range(len(train_ind), len(df_train_and_test))\n",
    "    #df_train_and_test.loc[len(train_ind), 'test_ind'] = test_ind\n",
    "    df_train_and_test.iloc[len(train_ind):, 3] =  test_ind # this works\n",
    "    #df_train_and_test.insert(loc=len(train_ind), column='test_ind', value=test_ind, allow_duplicates=False)\n",
    "    \n",
    "\n",
    "    # Check duplicates\n",
    "    #dupes = df_train_and_test.duplicated(subset=['train_ind'])\n",
    "\n",
    "    # 3. Pickle the dict.\n",
    "\n",
    "\n",
    "    output = df_train_and_test.to_dict('list')\n",
    "    \n",
    "    with open('./mlma_lvl_1_data.pkl', 'wb') as handle:\n",
    "       pickle.dump(output , handle)\n",
    "\n",
    "    # This is just for testing.\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['text', 'label']",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-24e01bc9f714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TRAC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/hate_speech_mlma/MLMA_convert/level1/train.tsv'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'../Data/hate_speech_mlma/MLMA_convert/level1/test.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-ba748d5409e3>\u001b[0m in \u001b[0;36mpickle_data\u001b[1;34m(train_file, test_file, type)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcols_to_use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols_to_use\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols_to_use\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2052\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2053\u001b[0m             ):\n\u001b[1;32m-> 2054\u001b[1;33m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\emsub\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[1;34m(usecols, names)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1303\u001b[0m             \u001b[1;34mf\"Usecols do not match columns, columns expected but not found: {missing}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['text', 'label']"
     ]
    }
   ],
   "source": [
    "# Function call\n",
    "\n",
    "# TRAC\n",
    "test = pickle_data('../Data/hate_speech_mlma/MLMA_convert/level1/train.tsv' , '../Data/hate_speech_mlma/MLMA_convert/level1/test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2392\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  texts                 info  \\\n",
       "0                                     Ready .... GO !!!  {'label': 'noHate'}   \n",
       "1     If i sent you some pic wound use be able to pu...  {'label': 'noHate'}   \n",
       "2     ALWAYS SPEAK OUT WHEN IN A CLASS WITH A BRAINW...  {'label': 'noHate'}   \n",
       "3     They fit the same DNA as the DNA found in anci...  {'label': 'noHate'}   \n",
       "4     I would not be surprised if this woman was spe...    {'label': 'hate'}   \n",
       "...                                                 ...                  ...   \n",
       "2387  Sometimes I do watch shows about WWII on the H...  {'label': 'noHate'}   \n",
       "2388  It 's a pretty powerful documentary that blew ...  {'label': 'noHate'}   \n",
       "2389  Like the parasites they are they simply moved ...    {'label': 'hate'}   \n",
       "2390  Their lies are so thick and many that people d...    {'label': 'hate'}   \n",
       "2391  We knew that these structures were built by su...  {'label': 'noHate'}   \n",
       "\n",
       "      train_ind  test_ind  val_ind  \n",
       "0        1616.0       NaN   1532.0  \n",
       "1        1678.0       NaN   1792.0  \n",
       "2         592.0       NaN    642.0  \n",
       "3        1224.0       NaN    181.0  \n",
       "4         395.0       NaN    795.0  \n",
       "...         ...       ...      ...  \n",
       "2387        NaN    2387.0      NaN  \n",
       "2388        NaN    2388.0      NaN  \n",
       "2389        NaN    2389.0      NaN  \n",
       "2390        NaN    2390.0      NaN  \n",
       "2391        NaN    2391.0      NaN  \n",
       "\n",
       "[2392 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n      <th>info</th>\n      <th>train_ind</th>\n      <th>test_ind</th>\n      <th>val_ind</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ready .... GO !!!</td>\n      <td>{'label': 'noHate'}</td>\n      <td>1616.0</td>\n      <td>NaN</td>\n      <td>1532.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>If i sent you some pic wound use be able to pu...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>1678.0</td>\n      <td>NaN</td>\n      <td>1792.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ALWAYS SPEAK OUT WHEN IN A CLASS WITH A BRAINW...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>592.0</td>\n      <td>NaN</td>\n      <td>642.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They fit the same DNA as the DNA found in anci...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>1224.0</td>\n      <td>NaN</td>\n      <td>181.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I would not be surprised if this woman was spe...</td>\n      <td>{'label': 'hate'}</td>\n      <td>395.0</td>\n      <td>NaN</td>\n      <td>795.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2387</th>\n      <td>Sometimes I do watch shows about WWII on the H...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>NaN</td>\n      <td>2387.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2388</th>\n      <td>It 's a pretty powerful documentary that blew ...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>NaN</td>\n      <td>2388.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2389</th>\n      <td>Like the parasites they are they simply moved ...</td>\n      <td>{'label': 'hate'}</td>\n      <td>NaN</td>\n      <td>2389.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2390</th>\n      <td>Their lies are so thick and many that people d...</td>\n      <td>{'label': 'hate'}</td>\n      <td>NaN</td>\n      <td>2390.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2391</th>\n      <td>We knew that these structures were built by su...</td>\n      <td>{'label': 'noHate'}</td>\n      <td>NaN</td>\n      <td>2391.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2392 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#test.keys()\n",
    "#test['texts'][:10]\n",
    "\n",
    "#print(' length', len(test['texts']))\n",
    "\n",
    "# Check if things align. (✔)\n",
    "\n",
    "#print(test['texts'][-1])\n",
    "#print(test['info'][-1:])\n",
    "#print(test['train_ind'][-1:])\n",
    "\n",
    "print(len(test['train_ind']))\n",
    "\n",
    "df_test = pd.DataFrame(test)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 <class 'dict'> dict_keys(['texts', 'info', 'train_ind', 'test_ind', 'val_ind'])\n14172\n"
     ]
    }
   ],
   "source": [
    "# inspect pickle file\n",
    "\n",
    "with open('./trac_data.pkl', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "print(len(data), type(data), data.keys())\n",
    "\n",
    "print(len(data['texts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}